% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tools.R
\name{test_parallel_computation}
\alias{test_parallel_computation}
\title{Testing parallel computing}
\usage{
test_parallel_computation(
  iter = 20L,
  nb_cores = 1L,
  list = NULL,
  cost = 1,
  lapply_pkg = "pbmcapply"
)
}
\arguments{
\item{iter}{the number of iteration to perform}

\item{nb_cores}{the number of CPU core(s) to use}

\item{list}{a list which length will be measured (optional)}

\item{cost}{the cost for the time threshold (default = 1; increase to speed up test, decrease to
lengthen it)}

\item{lapply_pkg}{the R package used to implement a \code{lapply()} kind of function (default =
"pbmcapply"; other possibilities are "parallel" and "base")}
}
\description{
This function is aimed at testing if the parallel computation run efficiently and you can use it
as a skeleton to benchmark alternative implementations. It simply runs loops that take, in turns,
\code{(1:iter)/cost} time to run. A large object may be supplied to the argument \code{list} to monitor how
the memory is being handled. For example, you may want to provided to \code{list} the output of the
function \code{\link{fit_life_histories}}.
}
\details{
We tried many implementation (using the R packages parallel, furrr, future.apply and foreach;
combined with the backends doSnow, doParallel, or doFuture; using either multi-threading or
multi-processing). At least on our linux system, the implementation used here simply using
\code{\link[parallel:mclapply]{mclapply}} outperformed all these alternatives. Using this function
introduces some restrictions: you must run it under a Unix based system and it is best to run it
directly in a terminal (as opposed within R-GUI or RStudio). Yet, it does combine keys features
suiting our purpose:
\itemize{
\item no time seems wasted doing heavy handed communication between tasks
\item the handling of the memory is best: objects that can be shared between tasks are indeed shared
and when a job is done, the memory is immediately released
\item it does not require any additional package.
}

Yet, since it is a little difficult to display progress properly using
\code{\link[parallel:mclapply]{mclapply}}, we used a small wrapper around it provided by
\code{\link[pbmcapply:pbmclapply]{pbmclapply}}. You can alternate between these two implementations by
setting the argument \code{lapply_pkg} to either \code{"parallel"} or \code{"pbmcapply"}. To use the function
sequentially you can also set the argument \code{lapply_pkg} to  \code{"base"}. This latter possibility
will run fine under Windows, but won't perform parallel computing.
}
\examples{
## sequential version, for reference:
test_parallel_computation(iter = 4L, nb_cores = 2L, lapply_pkg = "base")

## parallel version, using the R package parallel:
test_parallel_computation(iter = 4L, nb_cores = 2L, lapply_pkg = "parallel")

## parallel version, using the R package pbmcapply (if available):
## same with progression bar if pkg pbmcapply installed:
if (requireNamespace("pbmcapply", quietly = TRUE)){
  test_parallel_computation(iter = 4L, nb_cores = 2L)
}

}
