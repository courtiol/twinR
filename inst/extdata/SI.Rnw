\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage{amssymb,amsmath,bm,upgreek}
\usepackage[symbol]{footmisc}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage[margin=1in]{geometry}
\usepackage{flafter}
%\usepackage[sectionbib]{natbib}
\usepackage[style=nature, natbib=true]{biblatex}
\addbibresource{twin_SI.bib}

\newcommand{\adata}{\ensuremath{\mathcal{D}}}
\newcommand{\data}{\ensuremath{D}}
\newcommand{\datab}{\ensuremath{D_{b}^*}}
\newcommand{\databb}{\ensuremath{D_{bc}^{**}}}
\newcommand{\boo}[1]{\ensuremath{{#1}_{b}^{*}}}
\newcommand{\CDF}{\ensuremath{\mathrm{CDF}}}
\newcommand{\sfn}{\ensuremath{\mathrm{s}}}
\newcommand{\tfn}{\ensuremath{\mathrm{t}}}
\newcommand{\bth}{\ensuremath{\bm{\uptheta}}}
\newcommand{\bSigma}{\ensuremath{\boldsymbol{\Sigma}}}
\DeclareMathOperator{\Esp}{E}

\title{Supplementary Information for}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Mothers with higher twinning propensity had lower fertility in pre-industrial Europe}
\author{I. J. Rickard \and C. Vullioud \and F. Rousset \and E. Postma \and S.
Helle \and V. Lummaa \and R. Kylli \and J. E. Pettay \and E.
Røskaft \and G. R. Skjærvø \and C. Störmer \and E. Voland \and D.
Waldvogel \and A. Courtiol\footnote{corresponding author: courtiol@izw-berlin.de}}

\date{}

\begin{document}

\renewcommand{\figurename}{Supplementary Figure}
\renewcommand{\tablename}{Supplementary Table}
%\renewcommand{\thetable}{\arabic{table}}
%\renewcommand{\thefigure}{\arabic{figure}}
\renewcommand\refname{\textbf{Supplementary References}}

<<setup, include = FALSE>>=
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, error = TRUE, message = FALSE)
options(knitr.kable.NA = "")
library(twinR)
library(dplyr)
@

\maketitle

\tableofcontents

%\newpage

%\listoffigures

%\newpage

%\listoftables

\newpage

\section{Supplementary Notes}

We face the problem of testing Goodness-Of-Fit (GOF) when the distribution of the test statistic depends on fitted parameters, and we use a bootstrap procedure for that purpose. While this practice is widespread, it is widely ignored beyond the theoretical literature that this may be incorrect, so we first recall some theory and then consider corrections for this procedure.

We aim to assess whether the slope $s=\sfn(\adata)$ we estimate from the actual data \adata\ by the logistic regression (model 3; see Methods) between the per-birth twinning probability and maternal total births is consistent with the distribution $\phi(S=\sfn(\data) ; \bth)$ of slopes expected for samples $\data$ drawn under a given hypothetical scenario $\pi$ (say ``P'') with parameters $\bth$. We do not know the $\bth$ vector so we estimate it from the data, and the estimates  depend on the assumed $\pi$ (i.e., we obtain different estimates $\hat{\bth}_\pi$ for $\pi$=``P'', ``I'', and so on). Thus we use the slope as a GOF statistic for a model with parameters $\bth$ estimated aside of the slope, on the same data.

For a GOF test, we can then simulate the distribution $\phi(S;\hat{\bth}_\pi)$ and use this distribution as an approximation for $\phi(S; \bth)$. That is, we can obtain by simulation an estimate $\hat{\CDF}(x;\hat{\bth}_\pi)$ of the cumulative distribution function (CDF) of $S=\sfn(\data^*)$ for bootstrap samples $\data^*$ generated under $\hat{\bth}_\pi$, i.e., an estimate of $\Pr(S\leq x; \hat{\bth}_\pi)$ for any $x$, and determine a unidirectional p-value as the value of the estimated CDF value for observed slope, $p=\hat{\CDF}(\sfn(\adata) ;\hat{\bth}_\pi)$ (or $1-p$, depending on context). This is what a naive use of the bootstrap would provide.

However, we fitted parameters on the data, which means that the data tend to be more consistent with the fitted model $\phi(S;\hat{\bth}_\pi)$ than with the data-generating process $\phi(S; \bth)$. This means that, if a GOF test has controlled error rates (uniform p-values) when defined from $\CDF(x;\bth)$, it may be conservative when each sample is assessed against  $\CDF(x;\hat{\bth}_\pi)$, with parameters and CDF re-estimated on each sample produced by the data-generating process.

Whether the test is conservative depends on the relationship between the GOF statistic (more generally denoted $T=\tfn(D)$) and the estimated parameters. A toy example that captures this problem considers that $\bth$ is reduced to a single scalar parameter $\theta$, and that $\hat{\theta}(\data)$ follows jointly with $T$ the bivariate Gaussian model
\begin{equation*}
	\begin{pmatrix}T\\  \hat{\theta}\end{pmatrix} \sim \mathcal{N}\left(\boldsymbol{\mu}=\begin{pmatrix}\beta \theta\\ \theta\end{pmatrix}, \bSigma=\begin{pmatrix}
	\sigma^2_t+\beta^2 \sigma^2_{\hat{\theta}}& \beta \sigma^2_{\hat{\theta}}\\
	\beta \sigma^2_{\hat{\theta}}& \sigma^2_{\hat{\theta}}
	\end{pmatrix}\right)
\end{equation*}
with $\beta$, $\sigma^2_t$ and $\sigma^2_{\hat{\theta}}$ independent of $\theta$. The reason for considering this example is that it leads to a simple linear regression of $T$ to $\hat{\theta}$. Specifically, $T|\hat{\theta}; \theta \sim \mathcal{N}(\beta\hat{\theta},\sigma^2_t)$,%
%
\footnote[3]{From standard regression theory for gaussian variables: $T|\theta$ has mean $\Esp[T]+\bSigma_{12} \bSigma_{22}^{-1}(\hat{\theta}-\Esp(\hat{\theta}))$ and variance $\bSigma_{11}-\bSigma_{12} \bSigma_{22}^{-1}\bSigma_{12}$} %
%
from which some properties of the naive bootstrap test can easily be deduced. For this test, $T$ is compared to the distribution of $T^*$ values for bootstrap samples from the fitted model (i.e. with $\hat{\theta}$ as parameter). Therefore, for the test to be correct (with a uniform distribution of p-values), the conditional distribution of $T$ given $\hat{\theta}$ should be identical to the simulated distribution of the $T^*$s. But their variances are different: the conditional variance of $T$ is $\sigma^2_t$ (regression result), while the simulation variance is higher ($\sigma^2_t+\beta^2 \sigma^2_{\hat{\theta}}$, this being the same as the variance of $T$ drawn from the distribution with parameter $\theta$).  Various forms of non-uniform distributions of p-values may then result; the simplest one occurring when when $\beta=1$ and $\sigma^2_t$ reduces to zero. In that case the means of the two distributions are equal to $\hat{\theta}$, so the distribution of p-values concentrates on 0.5. Since this is true irrespective of the $\hat{\theta}$ value, the p-value will be generally too close to 0.5.

Conservativeness is expected whenever the GOF statistic is positively correlated with one of the parameter estimates. Ideally, one should use a GOF statistic whose distribution is (as least asymptotically) independent of the value of $\hat{\bth}_\pi$, or, equivalently in practice, of the value of $\bth$. In other words, the bootstrap procedure is guaranteed to provide an asymptotically correct GOF test of a statistic $T$ only if $T$ is asymptotically a pivotal statistic under the null model; a statistic being pivotal if its distribution is independent of the value of $\bth$. Using pivotal statistics is also a standard requirement for analytic GOF tests (e.g., \citealp{CoxH74}, §3.3).

Pivotal statistics are not generally available for use in one-step bootstrap procedures. In that case, double bootstrap procedures have been developed (e.g., \citealp{Beran88}; \citealp{DavisonH97}, p. 177).  The basic idea of such procedures is that, for each sample $\datab$ from the first bootstrap step, a second bootstrap is performed using bootstrap samples $\databb$ generated given the estimates $\hat{\bth}_\pi(\datab)$ (with $b=1,\ldots,B$) from the model fit to $\datab$, and $\tfn(\datab)$ can be compared to the distribution of $\tfn(\databb)$ (with $c=1,\ldots,C$) providing a value $\boo{p} = \hat{\CDF}(\tfn(\datab);\hat{\bth}_\pi(\datab) )$ for each $\datab$. The distribution of $\boo{p}$ would be uniform if $T$ were pivotal; instead of assuming that, one considers that the non-uniform distribution of $p= \hat{\CDF}(\tfn(\data);\hat{\bth}_\pi(\data))$ is asymptotically pivotal, and obtains an estimate of this distribution as that of \boo{p} over different $\datab$, by the double bootstrap calculation.

Double-bootstrap computations are computer intensive, and indeed not practically applicable as described above to the present problem. For such reasons, various simplifications of the above procedure have been discussed in the literature (\citealp{DavisonH97}, ch. 9). We apply here the notion of control variates, previously applied for bias correction in non-parametric bootstrap (ibid, Section 9.3; \citealp{Efron90}), as follows. A control variate is a variable correlated with $T$, which can be used to predict its value. The control variate that we consider here is (an estimator of) E$[S^*;\hat{\bth}_\pi(\data)]$, the expected value of the slope from samples drawn under the model fitted to \data. The test statistic of the corrected bootstrap test is then the residual of the prediction of the slope \sfn(\data)  by the mean value of $S^*$ under $\hat{\bth}_\pi(\data)$; the latter mean being obtained by performing a single-level bootstrap simulation. In the literature, simpler control variates have been considered, not requiring a bootstrap simulation; but these previous works considered non-parametric bootstrap simulations, which involve additional assumptions not valid here. In some of these previous works, parameter estimates (elements of $\hat{\bth}_\pi$) clearly correlated with $T$ have been used, in contrast to the present case.

More specifically, we apply the following procedure, which would be exact (apart from finite simulation error) under the toy model. Under the tested model, we draw $B$ replicates of $\data^*$ given $\hat{\bth}_\pi(\adata)$ and $C$ replicates of $\data^{**}$ given $\hat{\bth}_\pi(\data^*)$. We then perform a \emph{calibration} fit to construct a predictor of $\sfn(\datab)$ from the average value of $\sfn(\databb)$, by simple regression with intercept and slope. We use the residuals of prediction as GOF statistics. We use $B=200$ and $C=49$. We also performed \emph{validation} simulations that demonstrated the need for correcting the single-level bootstrap procedure and the effectiveness of our correction. For this validation, under each of the sixteen scenarios, we simulated $B_{\mathrm{v}}=200$ samples under the fitted model and applied to them both the single-level bootstrap test and the testing procedure with control variate. The resulting distributions are shown in Supplementary Figure 7, which confirms the need for a correction for models including mechanisms P and S.

Computationally, the main benefits of using a control variate over the raw double-bootstrap appear (a) when performing a single test, as fewer simulations may be needed to reach a given degree of accuracy in p-value determination; (b) when assessing the performance of the GOF test of an hypothesis $\pi_0$ under an alternative model $\pi_1$ (and in particular for the validation simulations, where $\pi_0 = \pi_1$). We first perform a double bootstrap simulation to obtain a calibration fit under $\pi_0$. Then, for each new sample \data\ generated under $\pi_1$, we do not need to perform a new double-bootstrap simulation. Instead, we need only to compute \sfn(\data), $\hat{\bth}_{\pi_0}(\data)$, and values of $\sfn(\data^*)$ for $C$ replicates of $\data^*$ simulated given $\hat{\bth}_{\pi_0}(\data)$, to obtain the residual of prediction of \sfn(\data)  from mean $\sfn(\data^*)$ and to compare it to the distribution of residuals from the single double bootstrap simulation on the original \data.

Despite the huge savings in computing brought by the control variate approach over a basic double bootstrap, our GOF tests of the different simulation scenarios still have large CPU and memory requirements. Such computations were performed both on a Linux computer with 128 cores and 254 GB of RAM from the Department of Evolutionary Genetics at the Leibniz Institute for Zoo and Wildlife Research (Berlin, Germany), as well as on a Linux cluster node with 112 cores and 3To of RAM of the Meso@LR cluster of the University of Montpellier, requiring a computation time of the order of 10,000 core CPU hours (about half of them for the validation).

\pagebreak


\section{Supplementary Figures}

\begin{figure}[H]
\begin{center}
\includegraphics[height = 6cm]{../figures/figS1.pdf}
\end{center}
\caption{Relationship between lifetime twinning status, maternal total births and the age at first birth (n=21,290 mothers in total, from 8 populations; see Table 1 in main text). The age at first birth was significantly higher for twinners with one ($\textrm{AFB}_\textrm{twinners}$ = 31.6 years; 95\% CI: 30.2, 33.0; $\textrm{AFB}_\textrm{non-twinners}$ = 29.3 years; 95\% CI 28.6, 30.0; delay for twinners = 27.5 months; 95\% CI: 11.9, 43.7) or two maternal total births ($\textrm{AFB}_\textrm{twinners}$ = 29.7 years; 95\% CI: 28.6, 30.8; $\textrm{AFB}_\textrm{non-twinners}$ = 28.2 years; 95\% CI: 27.5, 28.8; delay for twinners = 17.9 months; 95\% CI: 6.55, 29.4). Marginal predictions for the age at first reproduction are shown in black with open symbols. Their values are provided by the left y-axis. The distribution of maternal total births for both twinners and non-twinners is shown by the grey lines with filled symbols, with the numerical value given by the log-scaled y-axis on the right of the figure. 95\% CIs are shown as error bars and are based on 1000 parametric bootstrap replicates for each depicted category of maternal total births.}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height = 8.5cm]{../figures/figS2.pdf}
\end{center}
\caption{Relationships between the random effects for the three life history traits.
Top row (A-C) shows the relationship between the random effect from the fit of model 4 (the full model predicting parity progression; see Methods) and 6 (the full model predicting per-birth twinning probability). Bottom row (D-F) shows the relationship between the random effect from the fit of model 5 (the full model predicting the interbirth interval) and 6. Left column (A \& D) shows the relationship for mothers that did not produce any twins during their life. Middle column (B \& E) shows the relationship for mothers that produced twins once during their life. Right column (C \& F) shows the relationship for mothers that produced twins twice during their life. All axes are represented on the scale of the linear predictor of the corresponding models. Relationships for mothers that produced twins more than twice during their life are not displayed but follow similar patterns.}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height = 6cm]{../figures/figS3.pdf}
\end{center}
\caption{Hypothetical mechanisms tested by the simulation of alternative scenarios built around models predicting three life history events: parity progression (PP), interbirth interval (IBI) and twinning status of a given birth (T). The bubble on the left shows how the three life history models that were included in all simulation scenarios were modified to test each of the four hypothetical mechanisms (P, I, S, H; see section Results in main text for description). Each life history model describes the effect of predictors on a particular life history event. By default, each life history model includes an intercept and a random effect referring to the population. All models for PP and IBI also consider the effect of age/parity and maternal identity (see Methods). The bubble on the right shows the comprehensive set of combinations of the four mechanisms that were tested to produce simulation scenarios.}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[width = 0.9\linewidth]{../figures/figS4.pdf}
\end{center}
\caption{Representation of the four mechanisms (row 1) used as the basis for 16 simulation scenarios evaluated (all rows). Circles represent the three life history events we considered: parity progression (PP), probability of twinning (T) and interbirth interval (IBI). The rectangles represent the variables potentially shaping these life history events — maternal age and parity at a given birth (referred to as Age + Parity here; and as $\mathtt{poly(cbind(age, parity), best\_order)}$ in model formulas) and whether the last birth was a twin birth or not (Twin here; $\mathtt{twin}$ in model formulas) — as well as a random effect capturing other sources of heterogeneity between mothers (Maternal identity here; $\mathtt{maternal\_id}$ in model formulas). Black arrows represent relationships assumed in all simulation scenarios. Another random effect capturing differences between populations was also considered for all life history events and all mechanisms (not shown). Red arrows represent relationships used to activate the mechanisms required by each simulation scenario.}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height = 6cm]{../figures/figS5.pdf}
\end{center}
\caption{Relationship between the per-birth twinning probability and maternal total births (n=23,281 mothers in total, from 9 populations; see Supplementary Table 14). This figure reproduces the relationship shown in main text Fig. 2 (solid line for the regression line and grey area for the 95\% CI) but additionally plots the relationship with the inclusion of data from families with missing birth month information (including the entire Norway dataset). This latter relationship is illustrated by the dashed regression line with an estimated slope $\beta'$ of -0.0346 (95\% CI: -0.0511, -0.0183), as well as with the dotted lines showing the location of the 95\% CI.}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[height = 10cm]{../figures/figS6.pdf}
\end{center}
\caption{Comparison of different metrics between the real data and a dataset simulated under scenario PIS. A: distribution of maternal total births; B: number of twinners and non-twinners; C: distribution of maternal age at birth; D: number of singleton and twin births. The first row (A \& B) represents metrics computed at the level of mothers. The second row (C \& D) represents metrics computed at the level of births. All these plots show that the simulation scenario PIS produced fertility and twinning data similar to actual observations.}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[width = 0.9\linewidth]{../figures/figS7.pdf}
\end{center}
\caption{Evaluation of the validity of the goodness-of-fit testing procedure. Each plot shows the empirical cumulative distribution of p-values for each tested simulation scenario when the data were simulated under the same scenario. In such a case, the goodness-of-fit test corresponds to the test of the null hypothesis when the null hypothesis is true. Therefore, the probability density of p-values should be uniform and the cumulative distribution should appear close to the straight diagonal line depicted on the plots. However, the empirical cumulative distribution of p-values for the single-level bootstrap (shown in red) clearly departs from this expectation for scenarios including mechanisms P or S, showing that a correction is required. The empirical distributions of the double-bootstrap procedure (shown in blue) corrects this and show that the latter procedure can be applied for all scenarios.}
\end{figure}

\newpage

\section{Supplementary Tables}

\input{../tables/tableS01.tex}

\input{../tables/tableS02.tex}

\input{../tables/tableS03.tex}

\input{../tables/tableS04.tex}

\input{../tables/tableS05.tex}

\input{../tables/tableS06.tex}

\input{../tables/tableS07.tex}

\input{../tables/tableS08.tex}

\input{../tables/tableS09.tex}

\input{../tables/tableS10.tex}

\input{../tables/tableS11.tex}

\input{../tables/tableS12.tex}

\input{../tables/tableS13.tex}

\input{../tables/tableS14.tex}

%\bibliography{twin_SI}
\printbibliography

\end{document}

